{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3278b8c1-e9f5-496e-9c43-1497d004033c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bd03f-a39b-4451-ba82-62f12c5cec8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf7cef-dcba-4c28-80d9-2d77a6119a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skillsnetwork import cvstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77fdc5-9d1e-4787-b4b7-e323026b9e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:56<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cvstudioClient = cvstudio.CVStudio()\n",
    "\n",
    "cvstudioClient.downloadAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0310e6-1224-4cb4-98c3-8c349559fa03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations = cvstudioClient.get_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5e0cd-ceea-48b9-bf08-0bb29f2e1965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bda71ff4-ab41-4773-ba77-63a6294db7b0.jpg': [{'label': 'cat'}],\n",
       " 'afd11a5d-e4f2-4ce3-9b21-6e7ce39f54c4.jpg': [{'label': 'dog'}],\n",
       " '21c05b17-1dd4-4ada-b31d-52e288bc0716.jpg': [{'label': 'dog'}],\n",
       " 'e707705b-e005-4e0c-8ff3-c2e0f866915b.jpg': [{'label': 'dog'}],\n",
       " '0d441b55-cf07-4b6c-a868-71ff2ea01069.jpg': [{'label': 'cat'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_five = {k: annotations[\"annotations\"][k] for k in list(annotations[\"annotations\"])[:5]}\n",
    "first_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9f17f-7c8d-455f-8ff2-5fceef621621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_filename = 'images/' + random.choice(list(annotations[\"annotations\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21070d-08bb-4097-8060-6c0c4a2c3f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 is a cat\n",
      "Image 2 is a cat\n",
      "Image 3 is a cat\n",
      "Image 4 is a dog\n",
      "Image 5 is a cat\n",
      "Image 6 is a cat\n",
      "Image 7 is a dog\n",
      "Image 8 is a dog\n",
      "Image 9 is a cat\n",
      "Image 10 is a cat\n",
      "Image 11 is a cat\n",
      "Image 12 is a cat\n",
      "Image 13 is a dog\n",
      "Image 14 is a cat\n",
      "Image 15 is a cat\n",
      "Image 16 is a cat\n",
      "Image 17 is a cat\n",
      "Image 18 is a cat\n",
      "Image 19 is a cat\n",
      "Image 20 is a dog\n",
      "Image 21 is a dog\n",
      "Image 22 is a dog\n",
      "Image 23 is a dog\n",
      "Image 24 is a dog\n",
      "Image 25 is a cat\n",
      "Image 26 is a dog\n",
      "Image 27 is a dog\n",
      "Image 28 is a cat\n",
      "Image 29 is a dog\n",
      "Image 30 is a dog\n",
      "Image 31 is a dog\n",
      "Image 32 is a cat\n",
      "Image 33 is a dog\n",
      "Image 34 is a dog\n",
      "Image 35 is a cat\n",
      "Image 36 is a dog\n",
      "Image 37 is a cat\n",
      "Image 38 is a dog\n",
      "Image 39 is a cat\n",
      "Image 40 is a cat\n",
      "Image 41 is a dog\n",
      "Image 42 is a cat\n",
      "Image 43 is a dog\n",
      "Image 44 is a dog\n",
      "Image 45 is a dog\n",
      "Image 46 is a cat\n",
      "Image 47 is a cat\n",
      "Image 48 is a dog\n",
      "Image 49 is a cat\n",
      "Image 50 is a dog\n",
      "Image 51 is a cat\n",
      "Image 52 is a dog\n",
      "Image 53 is a dog\n",
      "Image 54 is a cat\n",
      "Image 55 is a dog\n",
      "Image 56 is a cat\n",
      "Image 57 is a dog\n",
      "Image 58 is a dog\n",
      "Image 59 is a dog\n",
      "Image 60 is a dog\n",
      "Image 61 is a dog\n",
      "Image 62 is a cat\n",
      "Image 63 is a dog\n",
      "Image 64 is a dog\n",
      "Image 65 is a dog\n",
      "Image 66 is a dog\n",
      "Image 67 is a dog\n",
      "Image 68 is a dog\n",
      "Image 69 is a dog\n",
      "Image 70 is a dog\n",
      "Image 71 is a cat\n",
      "Image 72 is a cat\n",
      "Image 73 is a cat\n",
      "Image 74 is a cat\n",
      "Image 75 is a dog\n",
      "Image 76 is a cat\n",
      "Image 77 is a dog\n",
      "Image 78 is a cat\n",
      "Image 79 is a cat\n",
      "Image 80 is a dog\n",
      "Image 81 is a cat\n",
      "Image 82 is a dog\n",
      "Image 83 is a dog\n",
      "Image 84 is a cat\n",
      "Image 85 is a cat\n",
      "Image 86 is a dog\n",
      "Image 87 is a cat\n",
      "Image 88 is a dog\n",
      "Image 89 is a dog\n",
      "Image 90 is a cat\n",
      "Image 91 is a cat\n",
      "Image 92 is a dog\n",
      "Image 93 is a cat\n",
      "Image 94 is a dog\n",
      "Image 95 is a dog\n",
      "Image 96 is a dog\n",
      "Image 97 is a cat\n",
      "Image 98 is a cat\n",
      "Image 99 is a cat\n",
      "Image 100 is a dog\n",
      "Image 101 is a dog\n",
      "Image 102 is a cat\n",
      "Image 103 is a cat\n",
      "Image 104 is a cat\n",
      "Image 105 is a dog\n",
      "Image 106 is a cat\n",
      "Image 107 is a dog\n",
      "Image 108 is a dog\n",
      "Image 109 is a cat\n",
      "Image 110 is a dog\n",
      "Image 111 is a cat\n",
      "Image 112 is a cat\n",
      "Image 113 is a dog\n",
      "Image 114 is a cat\n",
      "Image 115 is a dog\n",
      "Image 116 is a cat\n",
      "Image 117 is a cat\n",
      "Image 118 is a cat\n",
      "Image 119 is a dog\n",
      "Image 120 is a dog\n",
      "Image 121 is a dog\n",
      "Image 122 is a cat\n",
      "Image 123 is a dog\n",
      "Image 124 is a cat\n",
      "Image 125 is a cat\n",
      "Image 126 is a dog\n",
      "Image 127 is a cat\n",
      "Image 128 is a dog\n",
      "Image 129 is a cat\n",
      "Image 130 is a cat\n",
      "Image 131 is a cat\n",
      "Image 132 is a cat\n",
      "Image 133 is a cat\n",
      "Image 134 is a cat\n",
      "Image 135 is a dog\n",
      "Image 136 is a dog\n",
      "Image 137 is a dog\n",
      "Image 138 is a dog\n",
      "Image 139 is a cat\n",
      "Image 140 is a dog\n",
      "Image 141 is a cat\n",
      "Image 142 is a dog\n",
      "Image 143 is a cat\n",
      "Image 144 is a cat\n",
      "Image 145 is a dog\n",
      "Image 146 is a cat\n",
      "Image 147 is a cat\n",
      "Image 148 is a cat\n",
      "Image 149 is a cat\n",
      "Image 150 is a dog\n",
      "Image 151 is a cat\n",
      "Image 152 is a dog\n",
      "Image 153 is a dog\n",
      "Image 154 is a cat\n",
      "Image 155 is a dog\n",
      "Image 156 is a cat\n",
      "Image 157 is a cat\n",
      "Image 158 is a dog\n",
      "Image 159 is a cat\n",
      "Image 160 is a dog\n",
      "Image 161 is a cat\n",
      "Image 162 is a cat\n",
      "Image 163 is a cat\n",
      "Image 164 is a cat\n",
      "Image 165 is a dog\n",
      "Image 166 is a cat\n",
      "Image 167 is a cat\n",
      "Image 168 is a dog\n",
      "Image 169 is a dog\n",
      "Image 170 is a dog\n",
      "Image 171 is a cat\n",
      "Image 172 is a cat\n",
      "Image 173 is a cat\n",
      "Image 174 is a cat\n",
      "Image 175 is a dog\n",
      "Image 176 is a cat\n",
      "Image 177 is a dog\n",
      "Image 178 is a dog\n",
      "Image 179 is a dog\n",
      "Image 180 is a dog\n",
      "Image 181 is a cat\n",
      "Image 182 is a dog\n",
      "Image 183 is a dog\n",
      "Image 184 is a dog\n",
      "Image 185 is a dog\n",
      "Image 186 is a dog\n",
      "Image 187 is a dog\n",
      "Image 188 is a cat\n",
      "Image 189 is a dog\n",
      "Image 190 is a dog\n",
      "Image 191 is a cat\n",
      "Image 192 is a dog\n",
      "Image 193 is a dog\n",
      "Image 194 is a cat\n",
      "Image 195 is a cat\n",
      "Image 196 is a dog\n",
      "Image 197 is a cat\n",
      "Image 198 is a cat\n",
      "Image 199 is a dog\n",
      "Image 200 is a cat\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'.ipynb_checkpoints/01146abf-47a3-470e-8833-eb86ef16040e-checkpoint.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2070/3007640594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#label image using the annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"annotations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtmp_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"annotations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# resize image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '.ipynb_checkpoints/01146abf-47a3-470e-8833-eb86ef16040e-checkpoint.jpg'"
     ]
    }
   ],
   "source": [
    "image_paths = list(paths.list_images('images'))\n",
    "train_images = []\n",
    "train_labels = []\n",
    "class_object = annotations['labels']\n",
    "\n",
    "for (i, image_path) in enumerate(image_paths):\n",
    "    #read image\n",
    "    image = cv2.imread(image_path)\n",
    "    #make images gray\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    #label image using the annotations\n",
    "    label = class_object.index(annotations[\"annotations\"][image_path[7:]][0]['label'])\n",
    "    tmp_label = annotations[\"annotations\"][image_path[7:]][0]['label']\n",
    "    # resize image\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    # flatten the image\n",
    "    pixels = image.flatten()\n",
    "    #Append flattened image to\n",
    "    train_images.append(pixels)\n",
    "    train_labels.append(label)\n",
    "    print('Image', str(i+1), 'is a', tmp_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60185311-2283-410c-9478-bdacaa9614c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = np.array(train_images).astype('float32')\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9361ac-2d27-40f7-9958-123adfceb93c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(int)\n",
    "train_labels = train_labels.reshape((train_labels.size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb53f89-98f0-4dcd-b873-b2f9b2cfbef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "train_samples, test_samples, train_labels, test_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=test_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8717e9-f251-4849-8b23-55b768e893a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_datetime = datetime.now()\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_samples, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "## get different values of K\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "k_result = []\n",
    "for k in k_values:\n",
    "    ret,result,neighbours,dist = knn.findNearest(test_samples,k=k)\n",
    "    k_result.append(result)\n",
    "flattened = []\n",
    "for res in k_result:\n",
    "    flat_result = [item for sublist in res for item in sublist]\n",
    "    flattened.append(flat_result)\n",
    "\n",
    "end_datetime = datetime.now()\n",
    "print('Training Duration: ' + str(end_datetime-start_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07b96c-08c3-4779-a6fb-c50602f5263c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create an empty list to save accuracy and the cofusion matrix\n",
    "accuracy_res = []\n",
    "con_matrix = []\n",
    "## we will use a loop because we have multiple value of k\n",
    "for k_res in k_result:\n",
    "    label_names = [0, 1]\n",
    "    cmx = confusion_matrix(test_labels, k_res, labels=label_names)\n",
    "    con_matrix.append(cmx)\n",
    "    ## get values for when we predict accurately\n",
    "    matches = k_res==test_labels\n",
    "    correct = np.count_nonzero(matches)\n",
    "    ## calculate accuracy\n",
    "    accuracy = correct*100.0/result.size\n",
    "    accuracy_res.append(accuracy)\n",
    "## stor accuracy for later when we create the graph\n",
    "res_accuracy = {k_values[i]: accuracy_res[i] for i in range(len(k_values))}\n",
    "list_res = sorted(res_accuracy.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec685cd2-1f2e-4ee0-a376-81254670d27a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t=0\n",
    "## for each value of k we will create a confusion matrix\n",
    "for array in con_matrix:\n",
    "    df_cm = pd.DataFrame(array)\n",
    "    sns.set(font_scale=1.4) # for label size\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt = \".0f\") # font size\n",
    "    t += 1\n",
    "    title = \"Confusion Matrix for k equals \" + str(t)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804019a-6430-447d-9261-a2f37df27cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = zip(*list_res)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
